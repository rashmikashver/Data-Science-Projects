{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.)\n",
      "For K = 1:\n",
      "Confusion matrix =>\n",
      " [[671  54]\n",
      " [ 46   5]]\n",
      "\n",
      "Classification Accuracy = 87.113\n",
      "\n",
      "For K = 3:\n",
      "Confusion matrix =>\n",
      " [[707  18]\n",
      " [ 47   4]]\n",
      "\n",
      "Classification Accuracy = 91.624\n",
      "\n",
      "For K = 5:\n",
      "Confusion matrix =>\n",
      " [[718   7]\n",
      " [ 46   5]]\n",
      "\n",
      "Classification Accuracy = 93.170\n",
      "\n",
      "\n",
      "2.)\n",
      "For K = 1:\n",
      "Confusion matrix =>\n",
      " [[678  47]\n",
      " [ 42   9]]\n",
      "\n",
      "Classification Accuracy = 88.531\n",
      "\n",
      "For K = 3:\n",
      "Confusion matrix =>\n",
      " [[705  20]\n",
      " [ 44   7]]\n",
      "\n",
      "Classification Accuracy = 91.753\n",
      "\n",
      "For K = 5:\n",
      "Confusion matrix =>\n",
      " [[718   7]\n",
      " [ 48   3]]\n",
      "\n",
      "Classification Accuracy = 92.912\n",
      "\n",
      "\n",
      "3.)\n",
      "[[664  61]\n",
      " [ 35  16]]\n",
      "\n",
      "Accuracy = 0.876\n",
      "\n",
      "\n",
      "4.)\n",
      "Maximum accuracy for all three methods:\n",
      "KNN => 93.170\n",
      "\n",
      "KNN-normalized => 92.912\n",
      "\n",
      "Bayes => 87.629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "data = pd.read_csv('seismic_bumps1.csv')\n",
    "     \n",
    "k_value =[1,3,5]        \n",
    "remove_attributes = ['nbumps','nbumps2','nbumps3','nbumps4','nbumps5','nbumps6','nbumps7','nbumps89']\n",
    "data.drop(columns=remove_attributes, inplace=True)         \n",
    "        \n",
    "data_c0 = data[data['class'] == 0]  # 'class 0' Data\n",
    "data_c1 = data[data['class'] == 1]  # 'class 1' Data         \n",
    "        \n",
    "        \n",
    "x0 = data_c0.drop(columns=['class'])    # droping 'class' attribute \n",
    "x0_label = data_c0['class']             # storing 'class' \n",
    "\n",
    "x1 = data_c1.drop(columns=['class'])\n",
    "x1_label = data_c1['class']        \n",
    "        \n",
    "# Following will split data into training and testing datasets with 70% and 30% respectively\n",
    "x0_train, x0_test, x0_label_train, x0_label_test = train_test_split(x0, x0_label, test_size=0.3,random_state=42, shuffle=True) \n",
    "x1_train, x1_test, x1_label_train, x1_label_test = train_test_split(x1, x1_label, test_size=0.3,random_state=42, shuffle=True)\n",
    "\n",
    "x_train, x_test, x_label_train, x_label_test = x0_train.append(x1_train), x0_test.append(x1_test), x0_label_train.append(x1_label_train), x0_label_test.append(x1_label_test)  # combining both test and training samples of both example\n",
    "\n",
    "x_train.merge(x_label_train, left_index=True, right_index=True).to_csv('seismic-bumps-train.csv', index=False) \n",
    "x_test.merge(x_label_test, left_index=True, right_index=True).to_csv('seismic-bumps-test.csv', index=False)\n",
    "       \n",
    "accuracy = {'KNN': 0, 'KNN-normalized': 0, 'Bayes': 0}\n",
    "\n",
    "# Q1._______________________________________________________________\n",
    "print('\\n1.)')        \n",
    "for k in k_value: \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, x_label_train)     # fitting the model\n",
    "    x_label_pred = knn.predict(x_test)  # pridicting \n",
    "\n",
    "    accuracy['KNN'] = max(  accuracy['KNN'],accuracy_score(x_label_test,x_label_pred) * 100) # calculate accuracy\n",
    "    \n",
    "    print('For K = {}:'.format(k))\n",
    "    print('Confusion matrix =>\\n', confusion_matrix(x_label_test, x_label_pred))   # gives confusion matrix\n",
    "    print('\\nClassification Accuracy = {:.3f}\\n'.format(accuracy_score(x_label_test, x_label_pred)*100))  # gives classification accuracy\n",
    "        \n",
    "# Q2.___________________________________________________________________\n",
    "print('\\n2.)')        \n",
    "x_train_normalised = (x_train - x_train.min()) / (x_train.max() - x_train.min())  #normalizing train-data\n",
    "x_test_normalised = (x_test - x_train.min()) / (x_train.max() - x_train.min())  #normalizing test-data using min-max of train-data\n",
    "\n",
    "x_train_normalised.merge(x_label_train, left_index=True, right_index=True).to_csv('seismic-bumps-train-Normalised.csv', index=False)   # mereging to make save csv file of training data\n",
    "x_test_normalised.merge(x_label_test, left_index=True, right_index=True).to_csv('seismic-bumps-test-Normalised.csv', index=False)  # merging test data to save as csv\n",
    "\n",
    "for k in k_value:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)   # classifying data\n",
    "    knn.fit(x_train_normalised, x_label_train)   # fitting curve\n",
    "    x_label_pred = knn.predict(x_test_normalised)\n",
    "   \n",
    "    accuracy['KNN-normalized'] = max(accuracy['KNN-normalized'],accuracy_score(x_label_test, x_label_pred) * 100) # saving maximum accuracy of knn-normalized\n",
    "    print('For K = {}:'.format(k))\n",
    "    print('Confusion matrix =>\\n', confusion_matrix(x_label_test, x_label_pred)) #printing confusion matrix\n",
    "    print('\\nClassification Accuracy = {:.3f}\\n'.format(accuracy_score(x_label_test, x_label_pred)*100)) #printing accuracy of knn\n",
    "    \n",
    "# Q3.__________________________\n",
    "print('\\n3.)')            \n",
    "def fun(a,b): \n",
    "    c = [value for value in a if value in b] \n",
    "    return len(c)\n",
    "\n",
    "def maxLiklihood(m, covar , x):     # function to calcuate maximum likelihood\n",
    "    determinent = np.linalg.det(covar)    # determinent of covariance matrix\n",
    "    val = 1/(((2*np.pi)*5.)*determinent*0.5)    \n",
    "    signmainv = np.linalg.inv(covar);    # invariance of covariance matrix\n",
    "    firstparmeter = np.transpose(x-m);                   \n",
    "    firstparmeter = np.dot(firstparmeter,signmainv)\n",
    "    \n",
    "    finalparmeter = np.dot(firstparmeter,(x-m))  # mahalnobis distance\n",
    "    finalparmeter = -finalparmeter/2;\n",
    "    ans = val*np.exp(finalparmeter);   \n",
    "    return ans\n",
    "        \n",
    "mean_c0 = x0_train.mean()  #calculating mean of class0\n",
    "mean_c1 = x1_train.mean()  # calcuating mean of class1\n",
    "covar_c0 = np.cov(x0_train.T) # calculating covariance class0\n",
    "covar_c1 = np.cov(x1_train.T)  #calculating covariance of class1\n",
    "\n",
    "c1_predicted = []\n",
    "c0_predicted = []\n",
    "c1_actual = []\n",
    "c0_actual = []\n",
    "\n",
    "for i in x_test.index:\n",
    "   \n",
    "    m0 = maxLiklihood(mean_c0,covar_c0,x_test.loc[i])  # maximum likelihood with mean and covariance vector as class0\n",
    "    m1 = maxLiklihood(mean_c1,covar_c1,x_test.loc[i])  # maximum likelihood with mean and covariance vector as class1\n",
    "    m0 = m0*x0_train.size\n",
    "    m1 = m1*x1_train.size\n",
    "    if(m0>m1):\n",
    "        c0_predicted.append(i)  # append class according to maximum likelihood value\n",
    "    else:\n",
    "        c1_predicted.append(i)\n",
    "for index,items in x_label_test.iteritems():\n",
    "    if items==1:\n",
    "        c1_actual.append(index)  # append indics with actual class1\n",
    "    else:\n",
    "        c0_actual.append(index) # append indics with actual class0\n",
    "    \n",
    "\n",
    "c0_correct =   fun(c0_actual,c0_predicted)    # no. of samples whose class were correctly predicted as 0\n",
    "c1_correct =   fun(c1_actual,c1_predicted)    # whose class were correctly predicted as 1\n",
    "Class1Class0  =   len(c1_actual)-c1_correct   # whose class were wrongly predicted as 0\n",
    "Class0Class1  =   len(c0_actual)-c0_correct   # whose class were wrongly predicted as 1\n",
    "matrix = np.array([[c0_correct,Class0Class1],[Class1Class0,c1_correct]]) # gives confusion matrix\n",
    "\n",
    "Accuracy = (matrix[0][0] + matrix[1][1])/(matrix[1][1] + matrix[0][1] + matrix[1][0] + matrix[0][0]) # calculating accuracy\n",
    "print(matrix)\n",
    "print('\\nAccuracy = {:.3f}\\n'.format(Accuracy))\n",
    "accuracy['Bayes'] = max(Accuracy*100 , 0)\n",
    "\n",
    "# Q4._____________________________\n",
    "print('\\n4.)')\n",
    "print(\"Maximum accuracy for all three methods:\")\n",
    "for i in accuracy.keys():\n",
    "    print(i,end = \" \")\n",
    "    print('=> {:.3f}\\n'.format(accuracy[i]))  #gives maximum accuracy for all methods        \n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
